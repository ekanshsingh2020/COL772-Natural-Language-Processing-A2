{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions: 25000\n",
      "Number of tables: 25000\n",
      "Number of label columns: 25000\n",
      "Number of actual columns: 25000\n",
      "Number of label rows: 25000\n",
      "Number of questions: 5000\n",
      "Number of tables: 5000\n",
      "Number of label columns: 5000\n",
      "Number of actual columns: 5000\n",
      "Number of qids is  5000\n",
      "Number of label rows: 5000\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import gensim.downloader as api\n",
    "from gensim.test.utils import datapath\n",
    "import gensim\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "from unidecode import unidecode\n",
    "\n",
    "questions_train = []\n",
    "tables_train = []\n",
    "actual_col_train = []\n",
    "label_cols_train = []\n",
    "label_rows_train = []\n",
    "with open('data/A2_train.jsonl', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        parsed_data = json.loads(line)\n",
    "        questions_train.append(parsed_data['question'])\n",
    "        tables_train.append(parsed_data['table'])\n",
    "        label_cols_train.append(parsed_data['label_col'][0])\n",
    "        actual_col_train.append(list(parsed_data['table']['cols']))\n",
    "        label_rows_train.append(list(parsed_data['label_row']))\n",
    "\n",
    "# questions_train = clean_questions(questions_train)\n",
    "\n",
    "print('Number of questions:', len(questions_train))\n",
    "print('Number of tables:', len(tables_train))\n",
    "print('Number of label columns:', len(label_cols_train))\n",
    "print('Number of actual columns:', len(actual_col_train))\n",
    "print('Number of label rows:', len(label_rows_train))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "questions_test = []\n",
    "tables_test = []\n",
    "actual_col_test = []\n",
    "label_cols_test = []\n",
    "label_rows_test = []\n",
    "qid_test = []\n",
    "\n",
    "with open('data/A2_val.jsonl', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        parsed_data = json.loads(line)\n",
    "        questions_test.append(parsed_data['question'])\n",
    "        tables_test.append(parsed_data['table'])\n",
    "        label_cols_test.append(parsed_data['label_col'][0])\n",
    "        actual_col_test.append(list(parsed_data['table']['cols']))\n",
    "        qid_test.append(parsed_data['qid'])\n",
    "        label_rows_test.append(list(parsed_data['label_row']))\n",
    "\n",
    "# questions_test = clean_questions(questions_test)\n",
    "\n",
    "print('Number of questions:', len(questions_test))\n",
    "print('Number of tables:', len(tables_test))\n",
    "print('Number of label columns:', len(label_cols_test))\n",
    "print('Number of actual columns:', len(actual_col_test))\n",
    "print('Number of qids is ', len(qid_test))\n",
    "print('Number of label rows:', len(label_rows_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "label_set = []\n",
    "total_num_row =0\n",
    "for i in range(len(questions_train)):\n",
    "    question = unidecode(questions_train[i]).lower()\n",
    "    table = tables_train[i]\n",
    "    actual_col = actual_col_train[i]\n",
    "    label_row = label_rows_train[i]\n",
    "    for j in range(len(table['rows'])):\n",
    "        total_num_row+=1\n",
    "        row = table['rows'][j]\n",
    "        score = torch.empty(3)\n",
    "        for k in range(len(row)):\n",
    "            cell = unidecode(row[k]).lower()\n",
    "            that_col = unidecode(actual_col[k]).lower()\n",
    "            score[0]= score[0]+len(cell)\n",
    "            score[1]= score[1]+len(cell)*len(cell)\n",
    "            score[2]= score[2]+len(cell)*len(cell)*len(cell)\n",
    "        train_set.append(score)\n",
    "        if j in label_row:\n",
    "            label_set.append([0,1])\n",
    "        else:\n",
    "            label_set.append([1,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = torch.tensor(label_set, dtype=torch.float32)\n",
    "train_set = torch.stack(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(neuralNet,self).__init__()\n",
    "        self.first_layer = nn.Linear(3, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.second_layer = nn.Linear(10, 25)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.third_layer = nn.Linear(25, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.second_layer(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.third_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_model = neuralNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(row_model.parameters(), lr=0.005)\n",
    "row_model.train()\n",
    "epochs = 100\n",
    "for i in range(epochs):\n",
    "    # model.train()\n",
    "    acc_train = 0\n",
    "    optimizer.zero_grad()\n",
    "    outputs = row_model(train_set)\n",
    "    # print(outputs.shape)\n",
    "    # print(label_set.shape)\n",
    "    loss = criterion(outputs,label_set)\n",
    "    acc_train += (outputs.argmax(dim=1) == label_set.argmax(dim=1)).sum().item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # print('acc is ', acc_train/total_num_row)\n",
    "    row_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
